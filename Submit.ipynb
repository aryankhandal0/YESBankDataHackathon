{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def new_dataset(dataset, step_size):\n",
    "\tdata_X, data_Y = [], []\n",
    "\tfor i in range(len(dataset)-step_size-1): \n",
    "\t\ta = dataset[i:(i+step_size), 0]\n",
    "\t\tdata_X.append(a)\n",
    "\t\tdata_Y.append(dataset[i + step_size, 0])\n",
    "\treturn np.array(data_X), np.array(data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ab0ef930d398d273b02b58cd5880d3e3d4f292ee"
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate OHLC Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53681fa7398fc4f6e36a41ec652911310c1866ff"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../input/Training_data.csv', usecols=[2,3,4,5,6])\n",
    "#dataset = dataset[dataset['volume_sell']!=0]\n",
    "\n",
    "OHLC_avg = dataset[['opening_value','highest_value', 'lowest_value', 'settle_value']].mean(axis = 1)\n",
    "HLC_avg = dataset[['highest_value', 'lowest_value', 'settle_value']].mean(axis = 1)\n",
    "close_val = dataset[['settle_value']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data to make it compatible with the input of neural "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ea62a57462e6382561567cc6f9db1fc17b82fcc7"
   },
   "outputs": [],
   "source": [
    "obs = np.arange(1, len(dataset) + 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cd436e75de787f9183c16d60de66390ef977c2c9"
   },
   "outputs": [],
   "source": [
    "OHLC_avg = np.reshape(OHLC_avg.values, (len(OHLC_avg),1)) # 1664\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "OHLC_avg = scaler.fit_transform(OHLC_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d08c20211e924ee8712f704afc3c37b3ca685bb3"
   },
   "outputs": [],
   "source": [
    "y =  dataset['volume_sell']\n",
    "y = y.values\n",
    "y = scaler.fit_transform(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6d8e9b655ef77a44b1398496fa9c54c52b7d1746"
   },
   "outputs": [],
   "source": [
    "train_OHLC = int(len(OHLC_avg) * 0.75)\n",
    "test_OHLC = len(OHLC_avg) - train_OHLC\n",
    "x_train, x_test = OHLC_avg[0:train_OHLC,:], OHLC_avg[train_OHLC:len(OHLC_avg),:]\n",
    "y_train, y_test = y[0:train_OHLC,:], y[train_OHLC:len(OHLC_avg),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3e11611a9688470b3b897ba69bcfdbfeef015fcd"
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9418f251ad2e0c5423b9afa3e2d1923a0b6f1a43"
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], 1, x_train.shape[1]))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], 1, x_test.shape[1]))\n",
    "step_size = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Neural Network Layer by Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a6f56d8ea84e5ad9855ac662d24809476b37e5c"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(32, input_shape=(1, step_size), return_sequences = True))\n",
    "model.add(LSTM(16))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad') # Try SGD, adam, adagrad and compare!!!\n",
    "model.fit(x_train, y_train,validation_data=(x_test,y_test) , epochs=5, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0eeda87998418f3cda2260bba6a1ac68898d299c"
   },
   "outputs": [],
   "source": [
    "trainPredict = model.predict(x_train)\n",
    "testPredict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "59bf35f5c4daf133f6f5565a033c9ea91f4d5758"
   },
   "outputs": [],
   "source": [
    "trainPredict = scaler.inverse_transform(trainPredict)\n",
    "y_train = scaler.inverse_transform(y_train)\n",
    "testPredict = scaler.inverse_transform(testPredict)\n",
    "y_test = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11bf86da3fb5d792a1f6a4cf9366dbcf0338464e"
   },
   "outputs": [],
   "source": [
    "# TRAINING RMSE\n",
    "trainScore = math.sqrt(mean_squared_error(y_train, trainPredict[:,0]))\n",
    "print('Train RMSE: %.2f' % (trainScore))\n",
    "\n",
    "# TEST RMSE\n",
    "testScore = math.sqrt(mean_squared_error(y_test, testPredict[:,0]))\n",
    "print('Test RMSE: %.2f' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "641146418d88418643aa9367514e6bafe49c4471"
   },
   "outputs": [],
   "source": [
    "df_t = pd.read_csv(\"../input/Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5fd57c32cab117a5890d43b7e00b5b47e4f29e24"
   },
   "outputs": [],
   "source": [
    "OHLC_avg = df_t[['opening_value', 'highest_value', 'lowest_value', 'settle_value']].mean(axis = 1)\n",
    "HLC_avg = df_t[['highest_value', 'lowest_value', 'settle_value']].mean(axis = 1)\n",
    "close_val = df_t[['settle_value']]\n",
    "OHLC_avg = np.reshape(OHLC_avg.values, (len(OHLC_avg),1)) # 1664\n",
    "OHLC_avg = scaler.transform(OHLC_avg)\n",
    "obs = np.arange(1, len(dataset) + 1, 1)\n",
    "OHLC_avg = scaler.transform(OHLC_avg)\n",
    "X = np.reshape(OHLC_avg, (OHLC_avg.shape[0], 1, OHLC_avg.shape[1]))\n",
    "step_size = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8e15cdf85d221ad72ae73d46b4f3170f41f9bcc6"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(X)\n",
    "preds = scaler.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e3b780240343f88bdb1dd787c43cafed6877572a"
   },
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f99027d790426ed3ac1b9855f267fcf58bb28972"
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"../input/Test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c2bfbdc49ad5e424cc060753add2de933025076c"
   },
   "outputs": [],
   "source": [
    "serial = df2['serial_number']\n",
    "data = {'serial_number': serial, 'volume_sell': preds[:,0]}\n",
    "submission = pd.DataFrame(data)\n",
    "submission.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d939eb47546e0d6571e1f8c740c12c1e880be8f8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
